---
title: "Data Privacy"
author: "R package build"
date: '2022-04-12'
slug: data-privacy
categories: []
tags: []
---
# Initial Impressions:
##    The first thing that struck my attention as a viewer of the initial graph was the thought of "How could the data in different counties be correctly visualized when both averages for type of counties have a differnt y-axis scale? 
## When first looking at the representation the intended audience might be mislead by thinking that the averages over time have a very small difference, but is that really true?

# Observations after representing the data more accurately
## After I created a tribble with the time series of dates, I created a ggplot timeseries line plot that is colored by the different types of counties. From the new plot we can easily see how much more of a true difference there is between mask counties and no mask counties. It is also clear that no mask counties in Kansas have a significantly lower average of cases per 100k people. The reason for this easy identification is because instead of looking at 2 different scales of the y-axis, we are only looking at 1.

# Conclusions about Mask Wearing and COVID-19
## The conclusions that can be made about by looking at the true and better representation of COVID-19 averages is that mask wearing counties produces a significantly lower averages of cases when compared to counties that have no mask requirements. 

# 'Whats An Algorithm Got To Do With It' Review
## Kristen Lum discusses about what truly will make a model better at predicting future outcomes on unseen data. For starters, she mentions that for a model to be better at predicting unseen data, the data has to be arranged and sampled in a way that doesn't use biased data. What would happed to a machine learning model that uses biased data is that it would get so good at predicting off of that one portion of the data. Therefore if the model was retrained then the accuracy might keep increasing on the pure data but when retrained on biased data, the real world applications would produce higher errors when using that model. 
The importance of properly balancing a data set before modeling is a huge step in improving the model for unseen data. To balance a data set, it means that there is an equal proportion for a random samples to have one outcome or another. The example of this that Kristen Lum gave was data that was being used to predict drug crimes in certain areas in California. The data might show that it is more likely for a crime to happen in a specific area, but that can be from multiple factors. The main one is if people actually report it in that area. There might really be more crime in a different area but people there are less inclined to actually report it causing a lower presence of cops in the area to make the arrests. Therefore the data is considered to be biased to the areas where cops are actually looking more to stop the crimes from happening. She also mentioned the claim that white people are less likely to commit drug crimes. This can be proven to be wrong with true balanced data of cop presence in different areas. It might be true that they are arrested less, but only because cops are not looking or focused on that area. Therefore data balancing of under and over sampled data, although it might be hard for a data collector to initial collect this data will in turn how improve the models predictability of real world data. 

<script src="https://gist.github.com/spencergoldberg1/3d3cc334d75eb21a2046847b78afb150.js"></script>

